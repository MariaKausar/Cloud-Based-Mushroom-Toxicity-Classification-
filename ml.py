# -*- coding: utf-8 -*-
"""Maria_Kausar_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KRZz_wMF1BwN1hG_ZO8fYEG9X888u3gx
"""

# Import libraries
import mlflow
mlflow.pyspark.ml.autolog()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.sql.types import *
import pyspark.sql.functions as f

# List files in the directory
dbutils.fs.ls("/FileStore/tables")

# import mlflow and autolog machine learning runs
import mlflow
mlflow.pyspark.ml.autolog()

"""#Define Schema"""

# Importing necessary modules and types from PySpark
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType

# Defining the schema for the DataFrame
mySchema = StructType([
    StructField("member_id", IntegerType()),
    StructField("game", StringType()),
    StructField("behaviour", StringType()),
    StructField("hours", FloatType())
])

# Reading the CSV file into a DataFrame with specified schema
steam_200k = spark.read.csv("/FileStore/tables/steam_200k.csv", header=True, schema=mySchema)

# Displaying the first 5 rows
steam_200k.show(5, truncate=False)

"""#Exploratory Analysis"""

# Display the count of records for each member_id
steam_200k.groupBy("member_id").count().show(5)

# Display the top 5 members with the highest number of records
steam_200k.groupBy("member_id").count().orderBy("count", ascending=False).limit(5).display()

# Count the number of unique members and print
print("Number of Unique members are : {0}".format(steam_200k.select('member_id').distinct().count()))

# Count the number of unique games and print
print("Number of Unique games are : {0}".format(steam_200k.select('game').distinct().count()))

import matplotlib.pyplot as plt

# Count the number of unique members
num_unique_members = steam_200k.select('member_id').distinct().count()

# Count the number of unique games
num_unique_games = steam_200k.select('game').distinct().count()

# Plotting
plt.figure(figsize=(8, 4))
plt.bar(['Unique Members', 'Unique Games'], [num_unique_members, num_unique_games], color=['skyblue', 'orange'])
plt.xlabel('Categories')
plt.ylabel('Counts')
plt.title('Number of Unique Members vs Unique Games')
plt.grid(axis='y')
plt.show()

from pyspark.sql.functions import sum, round

# Group by game and sum the playing hours for each game
popular_games = steam_200k.where(steam_200k.behaviour == "play") \
                                  .groupBy("game") \
                                  .agg(sum("hours").alias("playing_hours")) \
                                  .orderBy("playing_hours", ascending=False)

# Rename the sum(hours) column to Playing_Hours
popular_games = popular_games.withColumnRenamed('playing_hours', 'playing_hours')

# Round the playing_hours column
popular_games = popular_games.withColumn('playing_hours', round('playing_hours'))

# Show the top 5 popular games
popular_games.show(5, truncate=False)

import matplotlib.pyplot as plt

# Convert the Spark DataFrame to a Pandas DataFrame for visualization
popular_games_df = popular_games.limit(5).toPandas()

# Plotting
plt.figure(figsize=(8, 4))
plt.bar(popular_games_df["game"], popular_games_df["playing_hours"], color='skyblue')
plt.xlabel('Game')
plt.ylabel('Playing Hours')
plt.title('Top 5 Popular Games by Playing Hours')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y')
plt.show()

from pyspark.sql.functions import sum, round

# Filter rows where behaviour is "play"
filtered_df = steam_200k.where(steam_200k.behaviour == "play")

# Group by member_id and sum the playing hours for each player
popular_players = filtered_df.groupBy("member_id") \
                             .agg(sum("hours").alias("Playing_Hours")) \
                             .orderBy("Playing_Hours", ascending=False)

# Round the Playing_Hours column
popular_players = popular_players.withColumn('Playing_Hours', round('Playing_Hours', 1))

# Show the top 5 popular players
popular_players.show(5, truncate=False)

# Make a DF for play behaviour
play_df = steam_200k.where(steam_200k.behaviour=="play")

play_df.show(5, truncate=False )

# DF for play behavior where hours are more than 1200
play_df = steam_200k.where((steam_200k.behaviour == "play") & (steam_200k.hours >= 1200))
play_df.show(5, truncate=False)

# DF for play behavior where hours are less than 200
play_df = steam_200k.where((steam_200k.behaviour == "play") & (steam_200k.hours <= 200))
play_df.show(5, truncate=False)

#make a DF for Purchase behaviour
purchase_df = steam_200k.where(steam_200k.behaviour=="purchase")

purchase_df.show(5, truncate=False )

"""# Data Pre-Processing"""

#drop null rows
steam_200k = steam_200k.dropna()
steam_200k.show(5)

# Loop through each column and count missing values
missing_values = {col: steam_200k.where(steam_200k[col].isNull()).count() for col in steam_200k.columns}

# Print the missing values for each column
for col, count in missing_values.items():
    print("Column '{}': {} missing values".format(col, count))

"""#Select "purchase" behaviour"""

from pyspark.sql.functions import col

# steam_200k is DataFrame
data = steam_200k.filter(col("behaviour") == "purchase").select("member_id", "game", "hours")

data.show(5)

"""#Assign integer ID value for the game"""

from pyspark.sql.window import Window
from pyspark.sql.functions import row_number
# Assign numerical IDs to game names
window = Window.orderBy("game")


# Generate game IDs
unique_gameID = data.select("game").distinct().withColumn("game_id", row_number().over(window))

# Show the generated game IDs (optional)
unique_gameID.show(5)

# Join the new dataframe with the original one to replace game names with game IDs
joined_data = data.join(unique_gameID, "game", "left").drop("game").withColumnRenamed("game_id", "game_id")

# Show the joined dataframe
joined_data.show(5)

# Split data into training and test sets (80% training, 20% test)
(training, test) = joined_data.randomSplit([0.8, 0.2])

import matplotlib.pyplot as plt

# Count the number of rows in each set
training_count = training.count()
test_count = test.count()

# Plotting
plt.figure(figsize=(8, 4))
plt.bar(["Training", "Test"], [training_count, test_count], color=['skyblue', 'orange'])
plt.xlabel('Dataset')
plt.ylabel('Number of Rows')
plt.title('Distribution of Data After Splitting into Training and Test Sets')
plt.grid(axis='y')
plt.show()

"""# Training the Model"""

# Import ALS from pyspark.ml.recommendation
from pyspark.ml.recommendation import ALS

# Define ALS model with specified parameters
als = ALS(maxIter=5,  # Maximum number of iterations
          regParam=0.01,  # Regularization parameter
          userCol="member_id",  # User column
          itemCol="game_id",  # Item column
          ratingCol="hours",  # Rating column
          coldStartStrategy="drop")  # Strategy for handling cold start issues

# Fit the ALS model to the training data
model = als.fit(training)

"""#Evaluation of the Model

"""

from pyspark.ml.evaluation import RegressionEvaluator
# Evaluate the model by computing the RMSE on the test data
predictions = model.transform(test).dropna()

# Create an evaluator to calculate RMSE
evaluator = RegressionEvaluator(metricName="rmse", labelCol="hours",
                                predictionCol="prediction")
rmse = evaluator.evaluate(predictions)

# Print the RMSE
print("Root-mean-square error is = " + str(rmse))

# Show the first 5 rows of the predictions DataFrame
predictions.show(5)

import matplotlib.pyplot as plt

# Convert predictions to Pandas DataFrame
predictions_df = predictions.select("hours", "prediction").toPandas()

# Plotting
plt.figure(figsize=(8, 4))
plt.scatter(predictions_df["hours"], predictions_df["prediction"], color='skyblue')
plt.plot([0, max(predictions_df["hours"])], [0, max(predictions_df["hours"])], color='orange', linestyle='--')
plt.xlabel('Actual Hours')
plt.ylabel('Predicted Hours')
plt.title('Actual vs Predicted Hours')
plt.grid(True)
plt.show()

# Setting up ALS model and parameter grid:

from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.recommendation import ALS

# Define ALS model with specified parameters
als = ALS(userCol="member_id", itemCol="game_id", ratingCol="hours", coldStartStrategy="drop", seed=100)

# Define parameter grid
parameters = ParamGridBuilder()\
    .addGrid(als.rank, [5, 10, 15])\
    .addGrid(als.regParam, [0.001, 0.005, 0.01, 0.05, 0.1])\
    .build()


#Setting up TrainValidationSplit:
from pyspark.ml.tuning import TrainValidationSplit
tvs = TrainValidationSplit()\
.setSeed(100)\
.setTrainRatio(0.75)\
.setEstimatorParamMaps(parameters)\
.setEstimator(als)\
.setEvaluator(evaluator)

#Fitting TrainValidationSplit to training data:
gridsearchModel = tvs.fit(training)

# Access the best model
bestModel = gridsearchModel.bestModel

# Print the parameters for the best model
print("Parameters for the best model:")
print("Rank Parameter: %g" % bestModel.rank)
print("RegParam Parameter: %g" % bestModel._java_obj.parent().getRegParam())

# Evaluate the best model on the test data
test_predictions = bestModel.transform(test)
test_rmse = evaluator.evaluate(test_predictions)

# Print the RMSE of the best model on the test data
print("Root Mean Squared Error (RMSE) on test data: %f" % test_rmse)

"""# General game recomendations for singular and all members"""

# Generate recommendations for all users
userRecs = model.recommendForAllUsers(5)

# Show the top 5 recommendations for each user with prediction
userRecs.show(5, truncate=False)

"""# Recomendation for specific member_id"""

# Specify the member_id for which you want recommendations
target_member_id =  5250

# Generate recommendations for the specified member_id
user_recommendations = gridsearchModel.bestModel.recommendForUserSubset(
    spark.createDataFrame([(target_member_id,)]).toDF("member_id"),
    numItems=10  # Specify how many recommendations you want to generate
)

# Show the recommendations
user_recommendations.show(truncate=False)

"""# Check with Different Hyperparameters"""

# Setting up ALS model and parameter grid:

from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.recommendation import ALS

# Define ALS model with specified parameters
als = ALS(userCol="member_id", itemCol="game_id", ratingCol="hours", coldStartStrategy="drop", seed=100)

# Define parameter grid
parameters = ParamGridBuilder()\
    .addGrid(als.rank, [10])\
    .addGrid(als.regParam, [0.005])\
    .build()


#Setting up TrainValidationSplit:
from pyspark.ml.tuning import TrainValidationSplit
tvs = TrainValidationSplit()\
.setSeed(100)\
.setTrainRatio(0.75)\
.setEstimatorParamMaps(parameters)\
.setEstimator(als)\
.setEvaluator(evaluator)

#Fitting TrainValidationSplit to training data:
gridsearchModel = tvs.fit(training)

# Access the best model
bestModel = gridsearchModel.bestModel

# Print the parameters for the best model
print("Parameters for the best model:")
print("Rank Parameter: %g" % bestModel.rank)
print("RegParam Parameter: %g" % bestModel._java_obj.parent().getRegParam())


# Evaluate the best model on the test data
test_predictions = bestModel.transform(test)
test_rmse = evaluator.evaluate(test_predictions)

# Print the RMSE of the best model on the test data
print("Root Mean Squared Error (RMSE) on test data: %f" % test_rmse)


# Specify the member_id 5250 for recommendations
target_member_id =  5250

# Generate recommendations for the specified member_id
user_recommendations = gridsearchModel.bestModel.recommendForUserSubset(
    spark.createDataFrame([(target_member_id,)]).toDF("member_id"),
    numItems=10  # Specify how many recommendations you want to generate
)

# Show the recommendations
user_recommendations.show(truncate=False)

# Setting up ALS model and parameter grid:

from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.recommendation import ALS

# Define ALS model with specified parameters
als = ALS(userCol="member_id", itemCol="game_id", ratingCol="hours", coldStartStrategy="drop", seed=100)

# Define parameter grid
parameters = ParamGridBuilder()\
    .addGrid(als.rank, [15])\
    .addGrid(als.regParam, [0.1])\
    .build()


#Setting up TrainValidationSplit:
from pyspark.ml.tuning import TrainValidationSplit
tvs = TrainValidationSplit()\
.setSeed(100)\
.setTrainRatio(0.75)\
.setEstimatorParamMaps(parameters)\
.setEstimator(als)\
.setEvaluator(evaluator)

#Fitting TrainValidationSplit to training data:
gridsearchModel = tvs.fit(training)

# Access the best model
bestModel = gridsearchModel.bestModel

# Print the parameters for the best model
print("Parameters for the best model:")
print("Rank Parameter: %g" % bestModel.rank)
print("RegParam Parameter: %g" % bestModel._java_obj.parent().getRegParam())


# Evaluate the best model on the test data
test_predictions = bestModel.transform(test)
test_rmse = evaluator.evaluate(test_predictions)

# Print the RMSE of the best model on the test data
print("Root Mean Squared Error (RMSE) on test data: %f" % test_rmse)


# Specify the member_id 5250 for recommendations
target_member_id =  5250

# Generate recommendations for the specified member_id
user_recommendations = gridsearchModel.bestModel.recommendForUserSubset(
    spark.createDataFrame([(target_member_id,)]).toDF("member_id"),
    numItems=10  # Specify how many recommendations you want to generate
)

# Show the recommendations
user_recommendations.show(truncate=False)

# Setting up ALS model and parameter grid:

from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.recommendation import ALS

# Define ALS model with specified parameters
als = ALS(userCol="member_id", itemCol="game_id", ratingCol="hours", coldStartStrategy="drop", seed=100)

# Define parameter grid
parameters = ParamGridBuilder()\
    .addGrid(als.rank, [10])\
    .addGrid(als.regParam, [0.001])\
    .build()


#Setting up TrainValidationSplit:
from pyspark.ml.tuning import TrainValidationSplit
tvs = TrainValidationSplit()\
.setSeed(100)\
.setTrainRatio(0.75)\
.setEstimatorParamMaps(parameters)\
.setEstimator(als)\
.setEvaluator(evaluator)

#Fitting TrainValidationSplit to training data:
gridsearchModel = tvs.fit(training)

# Access the best model
bestModel = gridsearchModel.bestModel

# Print the parameters for the best model
print("Parameters for the best model:")
print("Rank Parameter: %g" % bestModel.rank)
print("RegParam Parameter: %g" % bestModel._java_obj.parent().getRegParam())


# Evaluate the best model on the test data
test_predictions = bestModel.transform(test)
test_rmse = evaluator.evaluate(test_predictions)

# Print the RMSE of the best model on the test data
print("Root Mean Squared Error (RMSE) on test data: %f" % test_rmse)


# Specify the member_id 5250 for recommendations
target_member_id =  5250

# Generate recommendations for the specified member_id
user_recommendations = gridsearchModel.bestModel.recommendForUserSubset(
    spark.createDataFrame([(target_member_id,)]).toDF("member_id"),
    numItems=10  # Specify how many recommendations you want to generate
)

# Show the recommendations
user_recommendations.show(truncate=False)

# Setting up ALS model and parameter grid:

from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.recommendation import ALS

# Define ALS model with specified parameters
als = ALS(userCol="member_id", itemCol="game_id", ratingCol="hours", coldStartStrategy="drop", seed=100)

# Define parameter grid
parameters = ParamGridBuilder()\
    .addGrid(als.rank, [5])\
    .addGrid(als.regParam, [0.005])\
    .build()


#Setting up TrainValidationSplit:
from pyspark.ml.tuning import TrainValidationSplit
tvs = TrainValidationSplit()\
.setSeed(100)\
.setTrainRatio(0.75)\
.setEstimatorParamMaps(parameters)\
.setEstimator(als)\
.setEvaluator(evaluator)

#Fitting TrainValidationSplit to training data:
gridsearchModel = tvs.fit(training)

# Access the best model
bestModel = gridsearchModel.bestModel

# Print the parameters for the best model
print("Parameters for the best model:")
print("Rank Parameter: %g" % bestModel.rank)
print("RegParam Parameter: %g" % bestModel._java_obj.parent().getRegParam())



# Evaluate the best model on the test data
test_predictions = bestModel.transform(test)
test_rmse = evaluator.evaluate(test_predictions)

# Print the RMSE of the best model on the test data
print("Root Mean Squared Error (RMSE) on test data: %f" % test_rmse)



# Specify the member_id 5250 for recommendations
target_member_id =  5250

# Generate recommendations for the specified member_id
user_recommendations = gridsearchModel.bestModel.recommendForUserSubset(
    spark.createDataFrame([(target_member_id,)]).toDF("member_id"),
    numItems=10  # Specify how many recommendations you want to generate
)

# Show the recommendations
user_recommendations.show(truncate=False)

"""# Now on "play" behaviour"""

data = steam_200k.filter(col("behaviour") == "play").select("member_id", "game", "hours")

# Generate game IDs
unique_gameID = data.select("game").distinct().withColumn("game_id", row_number().over(window))

# Show the generated game IDs (optional)
unique_gameID.show(5)

# Join the new dataframe with the original one to replace game names with game IDs
joined_data = data.join(unique_gameID, "game", "left").drop("game").withColumnRenamed("game_id", "game_id")

# Show the joined dataframe
joined_data.show(5)

# Split data into training and test sets (80% training, 20% test)
(training, test) = joined_data.randomSplit([0.8, 0.2])

# Setting up ALS model and parameter grid:

from pyspark.ml.tuning import ParamGridBuilder
from pyspark.ml.recommendation import ALS

# Define ALS model with specified parameters
als = ALS(userCol="member_id", itemCol="game_id", ratingCol="hours", coldStartStrategy="drop", seed=100)

# Define parameter grid
parameters = ParamGridBuilder()\
    .addGrid(als.rank, [5, 10, 15])\
    .addGrid(als.regParam, [0.001, 0.005, 0.01, 0.05, 0.1])\
    .build()


#Setting up TrainValidationSplit:
from pyspark.ml.tuning import TrainValidationSplit
tvs = TrainValidationSplit()\
.setSeed(100)\
.setTrainRatio(0.75)\
.setEstimatorParamMaps(parameters)\
.setEstimator(als)\
.setEvaluator(evaluator)

#Fitting TrainValidationSplit to training data:
gridsearchModel = tvs.fit(training)


# Access the best model
bestModel = gridsearchModel.bestModel

# Print the parameters for the best model
print("Parameters for the best model:")
print("Rank Parameter: %g" % bestModel.rank)
print("RegParam Parameter: %g" % bestModel._java_obj.parent().getRegParam())

# Evaluate the best model on the test data
test_predictions = bestModel.transform(test)
test_rmse = evaluator.evaluate(test_predictions)

# Print the RMSE of the best model on the test data
print("Root Mean Squared Error (RMSE) on test data: %f" % test_rmse)

# Add a comment
# The RMSE value represents the average difference between the actual hours and predicted hours on the test data.
# Lower RMSE indicates better performance of the model.

# Generate recommendations for all users
userRecs = model.recommendForAllUsers(5)

# Show the top 5 recommendations for each user with prediction
userRecs.show(5, truncate=False)